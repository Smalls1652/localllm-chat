{
  "$schema": "https://schema.tauri.app/config/2",
  "productName": "LocalLLM Chat",
  "version": "0.1.0",
  "identifier": "online.smalls.locallm",
  "app": {
    "withGlobalTauri": true,
    "windows": [],
    "security": {
      "csp": null
    }
  },
  "build": {
    "removeUnusedCommands": false
  },
  "bundle": {
    "active": true,
    "targets": "app",
    "category": "Utility",
    "copyright": "Â© 2025 Smalls.Online",
    "homepage": "https://git.smalls.online/smalls/localllm-chat",
    "publisher": "Smalls.Online",
    "license": "MIT",
    "licenseFile": "LICENSE",
    "shortDescription": "A stupid way to run Open WebUI locally.",
    "longDescription": "A stupid way to run Open WebUI locally without having to manage the container resources manually.",
    "icon": [
      "icons/32.png",
      "icons/128.png",
      "icons/256.png",
      "icons/icon.icns"
    ]
  }
}